{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robsut Text Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to apply robust normalisation to preprocessed text data before textual analysis to improve model accuracy and reduce computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities will be removed from text are: \n",
    "- PERSON: Names of individuals.\n",
    "- ORG: Names of organizations, including companies, governmental entities, and other groups.\n",
    "- NORP: Nationalities, religious and political groups.\n",
    "- FAC: Facilities, like buildings, airports, highways, bridges.\n",
    "- GPE: Geo-political entities, such as countries, cities, states.\n",
    "- LOC: Non-GPE locations, mountain ranges, bodies of water.\n",
    "- PRODUCT: Objects, vehicles, foods, etc. (not services).\n",
    "- EVENT: Named events, such as battles, wars, sports events, hurricanes, etc.\n",
    "- WORK_OF_ART: Titles of books, songs, and other works of art.\n",
    "- LAW: Named documents made into laws, including directives, regulations, and legislative acts.\n",
    "- LANGUAGE: Any named language.\n",
    "- DATE: Absolute or relative dates or periods.\n",
    "- TIME: Times smaller than a day.\n",
    "- PERCENT: Percentage (including \"%\").\n",
    "- MONEY: Monetary values, including unit.\n",
    "- QUANTITY: Measurements, as of weight or distance.\n",
    "- ORDINAL: \"first\", \"second\", etc.\n",
    "- CARDINAL: Numerals that do not fall under another type (e.g., a counting number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We relied on spacy `EntityRecognizer` to identify the entities in the text. Due to our computational power constraints, the small model of spaCy web English which is `en_core_web_sm` was used instead of `en_core_web_trf` to trade some accuracy for speed and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzp98\\AppData\\Local\\Temp\\ipykernel_27388\\2569994772.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels_to_remove = [\"PERSON\", \"ORG\", \"NORP\", \"FAC\", \"GPE\", \"LOC\", \"PRODUCT\", \n",
    "                          \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\", \"DATE\", \"TIME\", \n",
    "                          \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"] # all possible entity in spacy entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define different normalisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise a text string, use with .apply()\n",
    "\n",
    "def normalise_text(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    ents_to_exclude_index = set()\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ent_labels_to_remove:\n",
    "            ents_to_exclude_index.update(range(ent.start, ent.end))\n",
    "\n",
    "    for token in doc:\n",
    "        if (\n",
    "            not token.like_url\n",
    "            and not token.like_email\n",
    "            and not token.is_stop\n",
    "            and not token.is_punct\n",
    "            and token.is_alpha\n",
    "            and token.i not in ents_to_exclude_index):\n",
    "                tokens.append(token.lemma_.lower())\n",
    "    return \" \".join(tokens)  # return a string\n",
    "    # return tokens # return a list\n",
    "\n",
    "\n",
    "def hash_to_word(test_text):\n",
    "    word = [nlp.vocab.strings[hash] for hash in test_text]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise a column in list form consists of spacy nlp object\n",
    "# this method is the fastest but consume huge memory at once\n",
    "\n",
    "def normalise_doc_at_once(nlp_object_column_list, ent_labels_to_remove):\n",
    "    results = []\n",
    "    for doc in tqdm(nlp_object_column_list):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            if (\n",
    "                not token.like_url\n",
    "                and not token.like_email\n",
    "                and not token.is_stop\n",
    "                and not token.is_punct\n",
    "                and token.is_alpha\n",
    "                and token.ent_type_ not in ent_labels_to_remove\n",
    "            ):\n",
    "                tokens.append(token.lemma_.lower())\n",
    "        results.append(\" \".join(tokens))\n",
    "    return results\n",
    "\n",
    "def column_to_nlp_object_list_at_once(a_df_column):\n",
    "    return list(tqdm(nlp.pipe(a_df_column.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise in batches to prevent out of memory error\n",
    "\n",
    "def normalise_doc(doc, ent_labels_to_remove):\n",
    "    tokens = [\n",
    "        token.lemma_.lower() for token in doc\n",
    "        if not token.like_url\n",
    "        and not token.like_email\n",
    "        and not token.is_stop\n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "        and token.ent_type_ not in ent_labels_to_remove\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def process_column_in_batches(df_column, batch_size=50000):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(df_column), batch_size)):\n",
    "        batch = df_column[i:i+batch_size].tolist()\n",
    "        docs = nlp.pipe(batch)\n",
    "        for doc in docs:\n",
    "            normalized_text = normalise_doc(doc, ent_labels_to_remove)\n",
    "            results.append(normalized_text)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzp98\\AppData\\Local\\Temp\\ipykernel_27388\\3202621294.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review = pd.read_csv('review.csv')\n"
     ]
    }
   ],
   "source": [
    "df_review = pd.read_csv('review.csv')\n",
    "# the warning was caused by uncleaned and mixed datatype in vote column, we will deal with this when we need vote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20566364 entries, 0 to 20566363\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   overall     float64\n",
      " 1   verified    bool   \n",
      " 2   reviewTime  object \n",
      " 3   asin        object \n",
      " 4   reviewText  object \n",
      " 5   vote        object \n",
      " 6   image       bool   \n",
      " 7   Year        int64  \n",
      " 8   price       float64\n",
      " 9   main_cat    object \n",
      "dtypes: bool(2), float64(2), int64(1), object(5)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there is no NA in reviewText column as this will cause error in spacy nlp.pipe\n",
    "df_review[\"reviewText\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_cat\n",
       "Computers                    6732262\n",
       "All Electronics              3655780\n",
       "Home Audio & Theater         3301869\n",
       "Camera & Photo               2502223\n",
       "Cell Phones & Accessories    2272921\n",
       "Car Electronics               412355\n",
       "Amazon Devices                296778\n",
       "Sports & Outdoors             221047\n",
       "Tools & Home Improvement      198603\n",
       "Office Products               172867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 10 main product category\n",
    "df_review['main_cat'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used for testing\n",
    "# df_review.info()\n",
    "# df_review_filter = df_review.loc[df_review[\"main_cat\"] == \"Computers\" ]\n",
    "# df_review_filter = df_review_filter.sample(100000, random_state=0)\n",
    "# df_review_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review_filter['reviewText'] = process_column_in_batches(df_review_filter['reviewText'], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review_filter['reviewText'].to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review_filter[\"reviewText\"] = normalise_list(column_to_nlp_object_list(df_review_filter[\"reviewText\"]), ent_labels_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review_filter['reviewText'].to_csv('test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used for testing\n",
    "# df_review_filter[\"reviewText\"] = normalise_list(column_to_nlp_object_list(df_review_filter[\"reviewText\"]), ent_labels_to_remove)\n",
    "# df_review_filter[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Camera & Photo  review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_camera = df_review.loc[df_review[\"main_cat\"] == \"Camera & Photo\" ]\n",
    "# df_review_camera.to_csv('review_camera.csv', index=False) # unnormalised version to csv if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12386       I was skeptical about buying a generic replace...\n",
       "12387       Battery arrived ahead of schedule and was 1/2 ...\n",
       "12388       Muy importante tener una batera cargada de rep...\n",
       "12389       The two rechargeable battery packs I ordered a...\n",
       "12390       Battery charged quickly and installed in my ca...\n",
       "                                  ...                        \n",
       "20566300    I love this dry box!!!! Besides being extremel...\n",
       "20566309    If you have more than day 5000 dollars of gear...\n",
       "20566310                                  Highly Recommended.\n",
       "20566313    I have been using this camera for about 5 mont...\n",
       "20566314    I enjoyed how durable and small this product i...\n",
       "Name: reviewText, Length: 2502223, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_camera[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [3:04:29<00:00, 217.05s/it]  \n",
      "C:\\Users\\rzp98\\AppData\\Local\\Temp\\ipykernel_27388\\3079339649.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_camera['reviewText'] = process_column_in_batches(df_review_camera['reviewText'], batch_size=50000) # adjust batch based on memory available (16G memory could handle around 50000 per batch)\n"
     ]
    }
   ],
   "source": [
    "df_review_camera['reviewText'] = process_column_in_batches(df_review_camera['reviewText'], batch_size=50000) # adjust batch based on memory available (16G memory could handle around 50000 per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12386       skeptical buy generic replacement battery new ...\n",
       "12387       battery arrive ahead schedule price anyplace b...\n",
       "12388       muy importante tener una batera cargada de rep...\n",
       "12389       rechargeable battery pack order work great cam...\n",
       "12390       battery charge quickly instal camera easily gr...\n",
       "                                  ...                        \n",
       "20566300    love dry box extremely functional allow displa...\n",
       "20566309    gear worth invest professional storage camera ...\n",
       "20566310                                     highly recommend\n",
       "20566313    camera truly k great video quality seriously g...\n",
       "20566314           enjoy durable small product bulky easy use\n",
       "Name: reviewText, Length: 2502223, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_camera['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_camera.to_csv('review_camera_normalised.csv', index=False)\n",
    "del df_review_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Cell Phones & Accessories review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_phone = df_review.loc[df_review[\"main_cat\"] == \"Cell Phones & Accessories\" ]\n",
    "# df_review_phone.to_csv('review_phone.csv', index=False) # unnormalised version to csv if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245        Stephanie has spent time filtering out many pr...\n",
       "1246        For the past two years I've taught math profic...\n",
       "1247        This book has notes, definitions,and practice ...\n",
       "1248        The resources in this book are like no other. ...\n",
       "1249        I am a High School mathematics teacher in the ...\n",
       "                                  ...                        \n",
       "20566349    Great product, great customer care. Thanks & w...\n",
       "20566350    Works great, love the longer cord. As with any...\n",
       "20566351    Perfect length. Very durable braiding. Works g...\n",
       "20566352    Ok here is an odd thing that happened to me, I...\n",
       "20566353                                          Works well.\n",
       "Name: reviewText, Length: 2272921, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_phone[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/46 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df_review_phone['reviewText'] = process_column_in_batches(df_review_phone['reviewText'], batch_size=50000) # adjust batch based on memory available (16G memory could handle around 50000 per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_phone['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_phone.to_csv('review_phone_normalised.csv', index=False)\n",
    "del df_review_phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Computer review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_comp = df_review.loc[df_review[\"main_cat\"] == \"Computers\" ]\n",
    "# df_review_comp.to_csv('review_computer.csv', index=False) # unnormalised version to csv if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743         It does 2A and charges a DEAD Nook in a few ho...\n",
       "744         Same charger can be bought at Barnes & Noble f...\n",
       "745         Works well, a little pricey I think for a char...\n",
       "746         My son crewed my HD charger cord so I needed a...\n",
       "747         It works perfect, puppy chewed last one and I ...\n",
       "                                  ...                        \n",
       "20566359    Had it 1 day and it quit working, will be retu...\n",
       "20566360    Received item in 2 days. Product worked as adv...\n",
       "20566361    I have it plugged into a usb extension on my g...\n",
       "20566362              Fast delivery product was simple to use\n",
       "20566363           Working as advertised, so far no problems.\n",
       "Name: reviewText, Length: 6732262, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_review_comp[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "485888it [40:24, 200.39it/s]"
     ]
    }
   ],
   "source": [
    "df_review_comp['reviewText'] = process_column_in_batches(df_review_comp['reviewText'], batch_size=50000) # adjust batch based on memory available (16G memory could handle around 5000 per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_comp['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_comp.to_csv('review_computer_normalised.csv', index=False)\n",
    "del df_review_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
